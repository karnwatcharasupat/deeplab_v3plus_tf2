{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b78b22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.applications import imagenet_utils\n",
    "from tensorflow.python.keras.layers import VersionAwareLayers\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "layers = VersionAwareLayers()\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v3 import *\n",
    "\n",
    "def MobileNetV3(stack_fn,\n",
    "                last_point_ch,\n",
    "                input_shape=None,\n",
    "                alpha=1.0,\n",
    "                model_type='large',\n",
    "                minimalistic=False,\n",
    "                include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                classes=1000,\n",
    "                pooling=None,\n",
    "                dropout_rate=0.2,\n",
    "                classifier_activation='softmax'):\n",
    "\n",
    "    # Determine proper input shape and default size.\n",
    "    # If both input_shape and input_tensor are used, they should match\n",
    "    if input_shape is not None and input_tensor is not None:\n",
    "        try:\n",
    "            is_input_t_tensor = backend.is_keras_tensor(input_tensor)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                is_input_t_tensor = backend.is_keras_tensor(\n",
    "                    layer_utils.get_source_inputs(input_tensor))\n",
    "            except ValueError:\n",
    "                raise ValueError('input_tensor: ', input_tensor,\n",
    "                                 'is not type input_tensor')\n",
    "        if is_input_t_tensor:\n",
    "            if backend.image_data_format == 'channels_first':\n",
    "                if backend.int_shape(input_tensor)[1] != input_shape[1]:\n",
    "                    raise ValueError('input_shape: ', input_shape, 'and input_tensor: ',\n",
    "                                     input_tensor,\n",
    "                                     'do not meet the same shape requirements')\n",
    "            else:\n",
    "                if backend.int_shape(input_tensor)[2] != input_shape[1]:\n",
    "                    raise ValueError('input_shape: ', input_shape, 'and input_tensor: ',\n",
    "                                     input_tensor,\n",
    "                                     'do not meet the same shape requirements')\n",
    "        else:\n",
    "            raise ValueError('input_tensor specified: ', input_tensor,\n",
    "                             'is not a keras tensor')\n",
    "\n",
    "    # If input_shape is None, infer shape from input_tensor\n",
    "    if input_shape is None and input_tensor is not None:\n",
    "\n",
    "        try:\n",
    "            backend.is_keras_tensor(input_tensor)\n",
    "        except ValueError:\n",
    "            raise ValueError('input_tensor: ', input_tensor, 'is type: ',\n",
    "                             type(input_tensor), 'which is not a valid type')\n",
    "\n",
    "        if backend.is_keras_tensor(input_tensor):\n",
    "            if backend.image_data_format() == 'channels_first':\n",
    "                rows = backend.int_shape(input_tensor)[2]\n",
    "                cols = backend.int_shape(input_tensor)[3]\n",
    "                input_shape = (3, cols, rows)\n",
    "            else:\n",
    "                rows = backend.int_shape(input_tensor)[1]\n",
    "                cols = backend.int_shape(input_tensor)[2]\n",
    "                input_shape = (cols, rows, 3)\n",
    "    # If input_shape is None and input_tensor is None using standart shape\n",
    "    if input_shape is None and input_tensor is None:\n",
    "        input_shape = (None, None, 3)\n",
    "\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        row_axis, col_axis = (0, 1)\n",
    "    else:\n",
    "        row_axis, col_axis = (1, 2)\n",
    "    rows = input_shape[row_axis]\n",
    "    cols = input_shape[col_axis]\n",
    "    if rows and cols and (rows < 32 or cols < 32):\n",
    "        raise ValueError('Input size must be at least 32x32; got `input_shape=' +\n",
    "                         str(input_shape) + '`')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    if minimalistic:\n",
    "        kernel = 3\n",
    "        activation = relu\n",
    "        se_ratio = None\n",
    "    else:\n",
    "        kernel = 5\n",
    "        activation = hard_swish\n",
    "        se_ratio = 0.25\n",
    "\n",
    "    x = img_input\n",
    "    x = layers.Rescaling(1. / 255.)(x)\n",
    "    x = layers.Conv2D(\n",
    "        16,\n",
    "        kernel_size=3,\n",
    "        strides=(2, 2),\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "        name='Conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis, epsilon=1e-3,\n",
    "        momentum=0.999, name='Conv/BatchNorm')(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    x = stack_fn(x, kernel, activation, se_ratio)\n",
    "\n",
    "    last_conv_ch = _depth(backend.int_shape(x)[channel_axis] * 6)\n",
    "\n",
    "    # if the width multiplier is greater than 1 we\n",
    "    # increase the number of output channels\n",
    "    if alpha > 1.0:\n",
    "        last_point_ch = _depth(last_point_ch * alpha)\n",
    "    x = layers.Conv2D(\n",
    "        last_conv_ch,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "        name='Conv_1')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis, epsilon=1e-3,\n",
    "        momentum=0.999, name='Conv_1/BatchNorm')(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = layer_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='MobilenetV3' + model_type)\n",
    "\n",
    "    return model\n",
    "\n",
    "def MobileNetV3Large(input_shape=None,\n",
    "                     alpha=1.0,\n",
    "                     minimalistic=False,\n",
    "                     include_top=True,\n",
    "                     weights='imagenet',\n",
    "                     input_tensor=None,\n",
    "                     classes=1000,\n",
    "                     pooling=None,\n",
    "                     dropout_rate=0.2,\n",
    "                     classifier_activation='softmax'):\n",
    "\n",
    "    def stack_fn(x, kernel, activation, se_ratio):\n",
    "\n",
    "        def depth(d):\n",
    "            return _depth(d * alpha)\n",
    "\n",
    "        x = _inverted_res_block(x, 1, depth(16), 3, 1, None, relu, 0)\n",
    "        x = _inverted_res_block(x, 4, depth(24), 3, 2, None, relu, 1)\n",
    "        x = _inverted_res_block(x, 3, depth(24), 3, 1, None, relu, 2)\n",
    "        x = _inverted_res_block(x, 3, depth(40), kernel, 2, se_ratio, relu, 3)\n",
    "        x = _inverted_res_block(x, 3, depth(40), kernel, 1, se_ratio, relu, 4)\n",
    "        x = _inverted_res_block(x, 3, depth(40), kernel, 1, se_ratio, relu, 5)\n",
    "        x = _inverted_res_block(x, 6, depth(80), 3, 2, None, activation, 6)\n",
    "        x = _inverted_res_block(x, 2.5, depth(80), 3, 1, None, activation, 7)\n",
    "        x = _inverted_res_block(x, 2.3, depth(80), 3, 1, None, activation, 8)\n",
    "        x = _inverted_res_block(x, 2.3, depth(80), 3, 1, None, activation, 9)\n",
    "        x = _inverted_res_block(x, 6, depth(112), 3, 1, se_ratio, activation, 10)\n",
    "        x = _inverted_res_block(x, 6, depth(112), 3, 1, se_ratio, activation, 11)\n",
    "        x = _inverted_res_block(x, 3, depth(80), kernel, 2, se_ratio, activation,\n",
    "                                12)\n",
    "        x = _inverted_res_block(x, 6, depth(80), kernel, 1, se_ratio, activation,\n",
    "                                13)\n",
    "        x = _inverted_res_block(x, 6, depth(80), kernel, 1, se_ratio, activation,\n",
    "                            14)\n",
    "        return x\n",
    "\n",
    "    return MobileNetV3(stack_fn, 1280, input_shape, alpha, 'large', minimalistic,\n",
    "                     include_top, weights, input_tensor, classes, pooling,\n",
    "                     dropout_rate, classifier_activation)\n",
    "\n",
    "def _depth(v, divisor=8, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _se_block(inputs, filters, se_ratio, prefix):\n",
    "    x = layers.GlobalAveragePooling2D(name=prefix + 'squeeze_excite/AvgPool')(\n",
    "        inputs)\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        x = layers.Reshape((filters, 1, 1))(x)\n",
    "    else:\n",
    "        x = layers.Reshape((1, 1, filters))(x)\n",
    "    x = layers.Conv2D(\n",
    "        _depth(filters * se_ratio),\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        name=prefix + 'squeeze_excite/Conv')(\n",
    "            x)\n",
    "    x = layers.ReLU(name=prefix + 'squeeze_excite/Relu')(x)\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        name=prefix + 'squeeze_excite/Conv_1')(\n",
    "            x)\n",
    "    x = hard_sigmoid(x)\n",
    "    x = layers.Multiply(name=prefix + 'squeeze_excite/Mul')([inputs, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def _inverted_res_block(x, expansion, filters, kernel_size, stride, se_ratio,\n",
    "                        activation, block_id):\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "    shortcut = x\n",
    "    prefix = 'expanded_conv/'\n",
    "    infilters = backend.int_shape(x)[channel_axis]\n",
    "    if block_id:\n",
    "        # Expand\n",
    "        prefix = 'expanded_conv_{}/'.format(block_id)\n",
    "        x = layers.Conv2D(\n",
    "            _depth(infilters * expansion),\n",
    "            kernel_size=1,\n",
    "            padding='same',\n",
    "            use_bias=False,\n",
    "            name=prefix + 'expand')(\n",
    "                x)\n",
    "        x = layers.BatchNormalization(\n",
    "            axis=channel_axis,\n",
    "            epsilon=1e-3,\n",
    "            momentum=0.999,\n",
    "            name=prefix + 'expand/BatchNorm')(\n",
    "                x)\n",
    "        x = activation(x)\n",
    "\n",
    "    if stride == 2:\n",
    "        x = layers.ZeroPadding2D(\n",
    "            padding=imagenet_utils.correct_pad(x, kernel_size),\n",
    "            name=prefix + 'depthwise/pad')(\n",
    "                x)\n",
    "    x = layers.DepthwiseConv2D(\n",
    "        kernel_size,\n",
    "        strides=stride,\n",
    "        padding='same' if stride == 1 else 'valid',\n",
    "        use_bias=False,\n",
    "        name=prefix + 'depthwise')(\n",
    "            x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis,\n",
    "        epsilon=1e-3,\n",
    "        momentum=0.999,\n",
    "        name=prefix + 'depthwise/BatchNorm')(\n",
    "            x)\n",
    "    x = activation(x)\n",
    "\n",
    "    if se_ratio:\n",
    "        x = _se_block(x, _depth(infilters * expansion), se_ratio, prefix)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "        name=prefix + 'project')(\n",
    "            x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis,\n",
    "        epsilon=1e-3,\n",
    "        momentum=0.999,\n",
    "        name=prefix + 'project/BatchNorm')(\n",
    "            x)\n",
    "\n",
    "    if stride == 1 and infilters == filters:\n",
    "        x = layers.Add(name=prefix + 'Add')([shortcut, x])\n",
    "        \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ac771de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mobilenetv3large_backbone(v1ckpt='/home/karn/deeplab_v3plus_tf2/deeplab_mnv3_large_cityscapes_trainfine/model.ckpt'):\n",
    "    \n",
    "    \n",
    "    def tf1_tf2_name_parser(tf2name):\n",
    "        newname = tf2name.split(':0')[0]\n",
    "\n",
    "        newname = newname.replace('kernel', 'weights')\n",
    "        newname = newname.replace('bias', 'biases')\n",
    "\n",
    "        newname = f\"MobilenetV3/{newname}\"\n",
    "\n",
    "        return newname\n",
    "    \n",
    "    LAST_LAYER = 270\n",
    "    \n",
    "    \n",
    "    \n",
    "    mn3 = MobileNetV3Large(include_top=False)\n",
    "                    \n",
    "    reader = tf.train.load_checkpoint(v1ckpt)\n",
    "    v1layers = sorted(reader.get_variable_to_shape_map().keys())\n",
    "    \n",
    "    not_found = []\n",
    "    not_used = [l for l in v1layers if (\"MobilenetV3/\" in l)]\n",
    "\n",
    "    for i, l in enumerate(mn3.layers):\n",
    "        if l.weights:\n",
    "            for w in l.weights:\n",
    "                tf1name = tf1_tf2_name_parser(w.name)\n",
    "                \n",
    "                pretrained = reader.get_tensor(tf1name)\n",
    "                \n",
    "                w.assign(pretrained)\n",
    "\n",
    "                if tf1name not in v1layers:\n",
    "                    not_found.append((w.name, tf1name))\n",
    "                else:\n",
    "                    not_used.remove(tf1name)\n",
    "\n",
    "    not_used = [l for l in not_used if \"Momentum\" not in l]\n",
    "    assert not not_used\n",
    "    assert not not_found\n",
    "                    \n",
    "    return mn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "757cf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn3 = make_mobilenetv3large_backbone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
